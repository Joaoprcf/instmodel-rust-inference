[package]
name = "instmodel_inference"
version = "0.6.0"
edition = "2024"
license = "MIT"
description = "High-performance neural network inference library with instruction-based execution"
repository = "https://github.com/Joaoprcf/instmodel-rust-inference"
keywords = ["neural-network", "inference", "machine-learning", "deep-learning"]
categories = ["science", "simulation"]
readme = "README.md"

[lib]
name = "instmodel_inference"
path = "src/lib.rs"

[[bin]]
name = "benchmark"
path = "benchmarks/bin/benchmark.rs"

[[bin]]
name = "gpu_benchmark"
path = "benchmarks/gpu/gpu_benchmark.rs"
required-features = ["gpu-benchmark"]

[features]
default = []
gpu-benchmark = ["wgpu", "pollster"]

[dependencies]
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
thiserror = "1.0"
log = "0.4"
env_logger = "0.10"
bytemuck = { version = "1.14", features = ["derive"] }

# Optional GPU dependencies (for benchmarks)
wgpu = { version = "24.0", optional = true }
pollster = { version = "0.4", optional = true }

[dev-dependencies]
pretty_assertions = "1.4"
wgpu = "24.0"
pollster = "0.4"
